// create-topic.js - Script ƒë·ªÉ t·∫°o topic v·ªõi replication factor cao
require('dotenv').config();
const { Kafka } = require('kafkajs');

const {
  KAFKA_BROKERS,
  KAFKA_TOPIC,
} = process.env;

async function createTopic() {
  console.log(`üîß T·∫°o topic "${KAFKA_TOPIC}" v·ªõi replication factor 3`);
  console.log(`üìç Connect v·ªõi broker: ${KAFKA_BROKERS}`);
  
  const kafka = new Kafka({
    clientId: 'topic-creator',
    brokers: KAFKA_BROKERS.split(',').map(s => s.trim()),
    logLevel: require('kafkajs').logLevel.INFO,
  });

  const admin = kafka.admin();

  try {
    await admin.connect();
    console.log('‚úÖ Connected to Kafka cluster');

    // T·∫°o topic v·ªõi replication factor 3 (cho 3 brokers)
    await admin.createTopics({
      topics: [{
        topic: KAFKA_TOPIC,
        numPartitions: 3, // 3 partitions
        replicationFactor: 3, // replicate tr√™n t·∫•t c·∫£ 3 brokers
        configEntries: [
          {
            name: 'cleanup.policy',
            value: 'delete'
          }
        ]
      }]
    });

    console.log(`‚úÖ Topic "${KAFKA_TOPIC}" ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!`);
    console.log(`üìä Partitions: 3, Replication Factor: 3`);
    
    // Hi·ªÉn th·ªã metadata c·ªßa topic
    const metadata = await admin.fetchTopicMetadata({ topics: [KAFKA_TOPIC] });
    console.log('\nüìã Topic Metadata:');
    console.log(JSON.stringify(metadata, null, 2));

  } catch (error) {
    if (error.type === 'TOPIC_ALREADY_EXISTS') {
      console.log(`‚ö†Ô∏è  Topic "${KAFKA_TOPIC}" ƒë√£ t·ªìn t·∫°i`);
    } else {
      console.error('‚ùå Error creating topic:', error);
    }
  } finally {
    await admin.disconnect();
    console.log('üëã Disconnected from Kafka cluster');
  }
}

createTopic().catch(console.error);
